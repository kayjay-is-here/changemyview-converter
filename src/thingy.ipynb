{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\yokon\\anaconda3\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: praw in c:\\users\\yokon\\anaconda3\\lib\\site-packages (7.6.1)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from praw) (0.58.0)\n",
      "Requirement already satisfied: update-checker>=0.18 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.1 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from praw) (2.3.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from prawcore<3,>=2.1->praw) (2.28.1)\n",
      "Requirement already satisfied: six in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from websocket-client>=0.54.0->praw) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2022.9.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.4)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\yokon\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\yokon\\anaconda3\\lib\\site-packages (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\yokon\\anaconda3\\lib\\site-packages (from pyarrow) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "# Install any dependencies\n",
    "!pip install pandas\n",
    "!pip install praw\n",
    "!pip install python-dotenv\n",
    "!pip install pyarrow"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "import os\n",
    "from os.path import join, dirname\n",
    "from dotenv import main\n",
    "\n",
    "# Make sure you create a .env file and fill in all the necessary information in the same folder as this script!\n",
    "main.load_dotenv(join(dirname(os.path.realpath('__file__')), '.env'))\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "   client_id=os.environ.get(\"CLIENT_ID\"),\n",
    "   client_secret=os.environ.get(\"CLIENT_SECRET\"),\n",
    "   user_agent=\"CMV_Scraper\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# load the data\n",
    "import tarfile\n",
    "import os.path\n",
    "import json\n",
    "import re\n",
    "from bz2 import BZ2File\n",
    "from urllib import request\n",
    "from io import BytesIO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "fname = \"cmv.tar.bz2\"\n",
    "url = \"https://chenhaot.com/data/cmv/\" + fname\n",
    "\n",
    "# download if not exists\n",
    "if not os.path.isfile(fname):\n",
    "    f = BytesIO()\n",
    "    with request.urlopen(url) as resp, open(fname, 'wb') as f_disk:\n",
    "        data = resp.read()\n",
    "        f_disk.write(data)  # save to disk too\n",
    "        f.write(data)\n",
    "        f.seek(0)\n",
    "else:\n",
    "    f = open(fname, 'rb')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ReadError",
     "evalue": "file could not be opened successfully",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mReadError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11256\\4017621961.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m#tar = tarfile.open(fileobj=f, mode=\"r:bz2\")\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mtar\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtarfile\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfileobj\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"r\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# Extract the file we are interested in\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\tarfile.py\u001B[0m in \u001B[0;36mopen\u001B[1;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001B[0m\n\u001B[0;32m   1623\u001B[0m                         \u001B[0mfileobj\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseek\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msaved_pos\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1624\u001B[0m                     \u001B[1;32mcontinue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1625\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mReadError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"file could not be opened successfully\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1626\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1627\u001B[0m         \u001B[1;32melif\u001B[0m \u001B[1;34m\":\"\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmode\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mReadError\u001B[0m: file could not be opened successfully"
     ]
    }
   ],
   "source": [
    "#tar = tarfile.open(fileobj=f, mode=\"r:bz2\")\n",
    "tar = tarfile.open(fileobj=f, mode=\"r\")\n",
    "\n",
    "# Extract the file we are interested in\n",
    "\n",
    "train_fname = \"op_task/train_op_data.jsonlist.bz2\"\n",
    "test_fname = \"op_task/heldout_op_data.jsonlist.bz2\"\n",
    "\n",
    "train_bzlist = tar.extractfile(train_fname)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_bzlist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_11256\\837332964.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# Load the jsonlist file into a dataframe\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_json\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_bzlist\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0morient\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'list'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlines\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'train_bzlist' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the jsonlist file into a dataframe\n",
    "df = pd.read_json(train_bzlist, orient='list', lines=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to check if the posts still exists on reddit\n",
    "def try_get_post(post_id):\n",
    "    try:\n",
    "        submission = reddit.submission(post_id)\n",
    "        submission.name\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        return False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the function that will be handling all the data gathering\n",
    "\n",
    "def get_top_comment_and_clean_data(post_id):\n",
    "    print(post_id)\n",
    "\n",
    "    # Grab the post\n",
    "    submission = reddit.submission(post_id)\n",
    "\n",
    "    # Grab the highest rated comment on root layer\n",
    "    submission.submission_type = 'best'\n",
    "    submission.comments.replace_more(limit=0)\n",
    "    replies = list(submission.comments)[0].replies.list()\n",
    "\n",
    "    # Just some variables\n",
    "    responses = pros = cons = []\n",
    "    last_author = submission.author.name\n",
    "    is_pro_argument = False\n",
    "\n",
    "    for comment in replies:\n",
    "        print(comment)\n",
    "        responses.append(comment.body)\n",
    "\n",
    "        # Sometimes for some reason duplicate entries exist\n",
    "        # Also remove automated message with \"Δ\" in it\n",
    "        if comment.body in responses or \"Δ\" in responses:\n",
    "            continue\n",
    "        \n",
    "        # If redditor object doesn't exist, the account is invalid/deleted\n",
    "        if not comment.author:\n",
    "            author = \"[deleted]\"\n",
    "            last_author = author\n",
    "            # There's no body text, so skip.\n",
    "            continue\n",
    "        else:\n",
    "            author = comment.author.name\n",
    "\n",
    "        # Assume that whenever the user changes, they are countering the previous person\n",
    "        if comment.author.name != last_author:\n",
    "            is_pro_argument = !is_pro_argument\n",
    "        \n",
    "        # Add to the respective argument type        \n",
    "        if is_pro_argument:\n",
    "            pros.append(comment.body)\n",
    "        else:\n",
    "            cons.append(comment.body)\n",
    "        \n",
    "        last_author = comment.author.name\n",
    "        \n",
    "    # Pros = arguments for the Title of this post\n",
    "    # Cons = arguments against the title of this post\n",
    "    \n",
    "    return pros, cons, responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.head(1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# load in our data. this will take a while.\n",
    "dataset = df.head(101)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "all_pros = all_names = all_titles = []\n",
    "\n",
    "for i in range(dataset.shape[0]):\n",
    "    post = dataset.iloc[i]\n",
    "    print(post.name)\n",
    "\n",
    "    if not try_get_post(post.name):\n",
    "        print(\"This shouldn't happen\")\n",
    "        continue\n",
    "\n",
    "    pros, _cons, _response = get_top_comment_and_clean_data(post['name'])\n",
    "    #print(pros)\n",
    "\n",
    "    all_pros.append(pros)\n",
    "    all_names.append(post.name)\n",
    "    all_titles.append(post.titles.replace('CMV', \"Change my mind\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Place it all into a Pandas Dataframe\n",
    "clean_df = pd.DataFrame({\n",
    "    \"INSTRUCTION\": all_titles,\n",
    "    \"RESPONSE\": all_pros,\n",
    "    \"SOURCE\": \"Reddit\"\n",
    "}, index=all_names\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Apache Paquete file\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "table = pa.Table.from_pandas(clean_df)\n",
    "pq.write_table(table,\"output.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
